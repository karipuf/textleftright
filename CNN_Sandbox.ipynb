{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "#############\n",
    "def doc2wv(instr):\n",
    "    '''\n",
    "    Converts sentences to word vectors\n",
    "    (first reduces all to lower case)\n",
    "    '''\n",
    "    res=[]\n",
    "    for word in (tmp.group().strip() for tmp in wordreg.finditer(instr.lower())):\n",
    "        try:\n",
    "            res.append(worddict[word])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return np.array(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "##########\n",
    "trainpath='../Naili_Data/traindata/'\n",
    "wordvecpath='/data/glove/glove.6B.50d.txt'\n",
    "wordreg=re.compile(\"\\S+\")\n",
    "nUnits=128\n",
    "embedDim=50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wlwoon/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Loading in data\n",
    "###################\n",
    "dat=load_files(trainpath)\n",
    "df=pd.read_csv(wordvecpath,sep=\"\\s\",skiprows=[8],names=['word']+['d'+str(tmp) for tmp in range(50)])\n",
    "worddict=dict(zip(df.word,df.iloc[:,1:].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating the network\n",
    "########################\n",
    "x=tf.placeholder(tf.float32,(None,None,embedDim))\n",
    "conv1=tf.nn.conv1d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
